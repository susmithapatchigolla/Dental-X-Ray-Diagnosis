{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " *Loading Keras model....\n",
      " * Model loaded!\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:50000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [07/Jun/2019 22:47:00] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7671751379966736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Jun/2019 22:47:14] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998482465744019\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from flask import request\n",
    "from flask import jsonify\n",
    "from flask import Flask\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import cv2\n",
    "app = Flask(__name__)\n",
    "def get_model():\n",
    "    #global model\n",
    "    #model=load_model('dentalalpha.h5')\n",
    "    model = keras.models.load_model('dentalalpha.h5')\n",
    "    #model._make_predict_function()\n",
    "    #graph = tf.get_default_graph()\n",
    "    print(\" * Model loaded!\")\n",
    "\n",
    "def preprocess_image(image,target_size):\n",
    "    if image.mode!=\"RGB\":\n",
    "        image=image.convert(\"RGB\")\n",
    "    \n",
    "    image = image.resize(target_size)\n",
    "    image=img_to_array(image)\n",
    "    image = np.expand_dims(image,axis=0)\n",
    "    return image\n",
    "print(\" *Loading Keras model....\")\n",
    "get_model()\n",
    "\n",
    "@app.route(\"/predict\",methods=[\"POST\"])\n",
    "def predict():\n",
    "   \n",
    "    message=request.get_json(force=True)\n",
    "    encoded=message['image']\n",
    "    #image_data=re.sub('^data:image/.+base64,','',encoded).decode('base64')\n",
    "    #image=Image.open(StringIO.StringIO(image_data))\n",
    "    decoded=base64.b64decode(encoded)\n",
    "    image=Image.open(io.BytesIO(decoded))\n",
    " \n",
    "    processed_image=preprocess_image(image,target_size=(224,224))\n",
    "    #global graph\n",
    "    #with graph.as_default():\n",
    "    prediction=model.predict(processed_image).tolist()\n",
    "    \n",
    "    response={\n",
    "        'prediction':\n",
    "        {\n",
    "            'dog':prediction[0][0],\n",
    "            'cat':1-prediction[0][0]\n",
    "            \n",
    "        }\n",
    "    }\n",
    "    print(prediction[0][0])\n",
    "    return jsonify(response)\n",
    "app.run(host='0.0.0.0', port=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
